###############################################
# LLM / OpenAI
###############################################
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_RETRIES=3
OPENAI_RETRY_BASE_DELAY=1.0

###############################################
# Backend selection: openai | ollama | basic
# 'basic' = heuristic fallback (no external API)
###############################################
LLM_BACKEND=basic

###############################################
# Allow automatic downgrade to heuristic summary
###############################################
ALLOW_BASIC_FALLBACK=1

###############################################
# Optional: Ollama local model (if using LLM_BACKEND=ollama)
###############################################
OLLAMA_MODEL=llama3
OLLAMA_BASE_URL=http://localhost:11434

###############################################
# Dev Frontend CORS origins (comma separated)
###############################################
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

###############################################
# Debug streaming logs (1 to enable)
###############################################
DEBUG_STREAM=0

###############################################
# Chunking defaults (override per request if needed)
###############################################
DEFAULT_CHUNK_SIZE=3000
DEFAULT_CHUNK_OVERLAP=300

###############################################
# Reserved for future (token caching, auth, etc.)
###############################################
# AUTH_TOKEN=
